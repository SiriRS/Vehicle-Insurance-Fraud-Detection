# -*- coding: utf-8 -*-
"""ImageDataModule_ImageCaption.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AYASCa62Q3gTcbUsHNFQDB0iUL2_5ePD

# Dataset
"""

import kagglehub
# Download latest version
path = kagglehub.dataset_download("harsh2040/wns-triange-hack-quest")
print("Path to dataset files:", path)

import os
dataset_path = "/root/.cache/kagglehub/datasets/harsh2040/wns-triange-hack-quest/versions/1"
print(os.listdir(dataset_path))

import os
from sklearn.model_selection import train_test_split
dataset_path = "/root/.cache/kagglehub/datasets/harsh2040/wns-triange-hack-quest/versions/1"
train_folder = os.path.join(dataset_path, "train (1)")
test_folder = os.path.join(dataset_path, "test (1)")

subdirs = [d for d in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, d))]
print("Subdirectories inside train (1):", subdirs)
if subdirs:
    sample_subdir = os.path.join(train_folder, subdirs[0])  # Pick first subdirectory
    sample_images = [f for f in os.listdir(sample_subdir) if f.endswith(('.jpg', '.png', '.jpeg'))]
    print(f"Sample images inside {subdirs[0]}:", sample_images[:5])

train_inner_folder = os.path.join(train_folder, "train")  # Path to nested 'train' folder
print("Files inside train folder:", os.listdir(train_inner_folder)[:10])  # Show first 10 items

import pandas as pd
csv_path = os.path.join(train_inner_folder, "train.csv")
train_data = pd.read_csv(csv_path)
print(train_data.head())  # Check first few rows

image_folder = os.path.join(train_inner_folder, "images")  # Path to images folder
train_data["filepath"] = train_data["filename"].apply(lambda x: os.path.join(image_folder, x))
train_labels = train_data["label"].astype(str)
print(train_data.head())  # Verify paths

from sklearn.model_selection import train_test_split
train_images, val_images, train_labels, val_labels = train_test_split(
    train_data["filepath"], train_labels, test_size=0.2, random_state=42
)

from sklearn.model_selection import train_test_split
# Define image paths and labels
image_paths = train_data["filepath"].tolist()
labels = train_data["label"].astype(str).tolist()  # Convert labels to string if needed
# Split into training and validation sets
train_images, val_images, train_labels, val_labels = train_test_split(
    image_paths, labels, test_size=0.2, random_state=42
)
# Print samples
print("Training samples:", train_images[:5])
print("Validation samples:", val_images[:5])

"""# CNN"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

# Step 1: Load and preprocess image data
IMG_SIZE = (128, 128)  # Resize all images to 128x128
def load_and_preprocess_image(path):
    img = load_img(path, target_size=IMG_SIZE)
    img_array = img_to_array(img)
    img_array = img_array / 255.0  # Normalize to [0, 1]
    return img_array

# Load training and validation data
X_train = np.array([load_and_preprocess_image(p) for p in train_images])
X_val = np.array([load_and_preprocess_image(p) for p in val_images])

# Convert labels to numerical classes
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_train = le.fit_transform(train_labels)
y_val = le.transform(val_labels)

# One-hot encode labels
num_classes = len(np.unique(y_train))
y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_val = tf.keras.utils.to_categorical(y_val, num_classes)

# Step 2: Build CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(*IMG_SIZE, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')
])

# Step 3: Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Step 4: Train the model
history = model.fit(
    X_train, y_train,
    epochs=15,
    batch_size=32,
    validation_data=(X_val, y_val)
)

model.save('cnn_model.h5')

"""#Mobilenet

"""

import os
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
import tensorflow as tf

# Your existing code to load and prepare data
dataset_path = "/root/.cache/kagglehub/datasets/harsh2040/wns-triange-hack-quest/versions/1"
train_folder = os.path.join(dataset_path, "train (1)")
train_inner_folder = os.path.join(train_folder, "train")
csv_path = os.path.join(train_inner_folder, "train.csv")
image_folder = os.path.join(train_inner_folder, "images")

# Load CSV and add file paths
train_data = pd.read_csv(csv_path)
train_data["filepath"] = train_data["filename"].apply(lambda x: os.path.join(image_folder, x))
train_data['label'] = train_data['label'].astype(str)
# Split into train and validation DataFrames
train_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42)

# Determine number of classes
num_classes = train_data["label"].nunique()
print("Number of classes:", num_classes)

# Define data generators with preprocessing suitable for MobileNetV2
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Scales images to [-1, 1] as expected by MobileNetV2
    rotation_range=20,        # Randomly rotate images
    width_shift_range=0.2,    # Randomly shift width
    height_shift_range=0.2,   # Randomly shift height
    horizontal_flip=True      # Randomly flip horizontally
)

val_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input  # Only preprocessing, no augmentation for validation
)

# Create generators from DataFrames
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    x_col="filepath",
    y_col="label",
    target_size=(128, 128),   # Resize images to 128x128
    batch_size=32,
    class_mode="categorical"  # Multi-class classification
)

val_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    x_col="filepath",
    y_col="label",
    target_size=(128, 128),
    batch_size=32,
    class_mode="categorical"
)

# Build the CNN model using MobileNetV2 with transfer learning
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
base_model.trainable = False  # Freeze the base model initially

model = Sequential([
    base_model,
    GlobalAveragePooling2D(),         # Reduces spatial dimensions
    Dense(512, activation='relu'),    # Fully connected layer
    Dense(num_classes, activation='softmax')  # Output layer for num_classes
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Define training parameters
steps_per_epoch = len(train_df) // 32
validation_steps = len(val_df) // 32

# Callbacks for better training
early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=50,  # Large number, early stopping will halt it
    validation_data=val_generator,
    validation_steps=validation_steps,
    callbacks=[early_stopping, model_checkpoint, reduce_lr]
)

# Optional: Fine-tune the model
base_model.trainable = True
# Freeze the first 100 layers (fine-tune the rest)
for layer in base_model.layers[:100]:
    layer.trainable = False

# Recompile with a smaller learning rate for fine-tuning
model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Fine-tune
history_fine = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=10,
    validation_data=val_generator,
    validation_steps=validation_steps
)

# Evaluate the model
val_loss, val_accuracy = model.evaluate(val_generator, steps=validation_steps)
print(f"Validation Accuracy: {val_accuracy * 100:.2f}%")

model.save('mobilenetv2.h5')model.save('mobilenetv2.h5')

import os
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import load_model
import numpy as np

# Define paths
dataset_path = "/root/.cache/kagglehub/datasets/harsh2040/wns-triange-hack-quest/versions/1"
test_folder = os.path.join(dataset_path, "test (1)")
test_inner_folder = os.path.join(test_folder, "test")  # Correct level
test_csv_path = os.path.join(test_inner_folder, "test.csv")
test_image_folder = os.path.join(test_inner_folder, "images")

# Debugging: Verify paths and existence
print("Test Folder:", test_folder)
print("Test Inner Folder:", test_inner_folder)
print("Test CSV Path:", test_csv_path)
print("Test Image Folder:", test_image_folder)
print("CSV Exists:", os.path.exists(test_csv_path))
print("Contents of test folder:", os.listdir(test_inner_folder))

# Load test CSV
test_data = pd.read_csv(test_csv_path)
test_data["filepath"] = test_data["filename"].apply(lambda x: os.path.join(test_image_folder, x))

# Verify test data
print("Test data sample:")
print(test_data.head())
print("Number of test samples:", len(test_data))

# Define test data generator
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_data,
    x_col="filepath",
    y_col=None,
    target_size=(128, 128),
    batch_size=32,
    class_mode=None,
    shuffle=False
)

# Load the trained model
model = load_model('mobilenetv2.h5')

# Make predictions
predictions = model.predict(test_generator, steps=len(test_data) // 32 + 1)

# Convert predictions to class labels
train_csv_path = os.path.join(dataset_path, "train (1)", "train", "train.csv")
train_data = pd.read_csv(train_csv_path)
class_labels = sorted(train_data["label"].unique())
predicted_classes = np.argmax(predictions, axis=1)
predicted_labels = [class_labels[idx] for idx in predicted_classes]

# Create and save results
results = pd.DataFrame({
    "filename": test_data["filename"],
    "predicted_label": predicted_labels
})
results.to_csv("test_predictions.csv", index=False)
print("Predictions saved to 'test_predictions.csv'")
print("Sample predictions:")
print(results.head())

import os
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import load_model
import numpy as np
import kagglehub
import glob

# Re-download dataset to ensure it's present
print("Re-downloading dataset...")
path = kagglehub.dataset_download("harsh2040/wns-triange-hack-quest", force_download=True)
print("Downloaded to:", path)

# Define paths based on downloaded location
dataset_path = path
test_folder = os.path.join(dataset_path, "test (1)")
test_inner_folder = os.path.join(test_folder, "test")
test_csv_path = os.path.join(test_inner_folder, "test.csv")
test_image_folder = os.path.join(test_inner_folder, "images")

# Debugging: Verify environment and paths
print("Current Working Directory:", os.getcwd())
print("Dataset Path:", dataset_path)
print("Test Folder:", test_folder)
print("Test Inner Folder:", test_inner_folder)
print("Test CSV Path:", test_csv_path)
print("Test Image Folder:", test_image_folder)
print("CSV Exists:", os.path.exists(test_csv_path))
print("Contents of test folder:", os.listdir(test_inner_folder))
print("All files in test folder:", glob.glob(os.path.join(test_inner_folder, "*")))

# Load test CSV
test_data = pd.read_csv(test_csv_path)
test_data["filepath"] = test_data["filename"].apply(lambda x: os.path.join(test_image_folder, x))

# Verify test data
print("Test data sample:")
print(test_data.head())
print("Number of test samples:", len(test_data))

# Rest of your code (data generator, predictions, etc.)...

import os
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import load_model
import numpy as np

# Define paths for Kaggle environment
dataset_path = "/kaggle/input/wns-triange-hack-quest"
test_folder = os.path.join(dataset_path, "test (1)")
test_inner_folder = os.path.join(test_folder, "test")
test_csv_path = os.path.join(test_inner_folder, "test.csv")
test_image_folder = os.path.join(test_inner_folder, "images")

# Debugging: Verify paths and existence
print("Dataset Path:", dataset_path)
print("Test Folder:", test_folder)
print("Test Inner Folder:", test_inner_folder)
print("Test CSV Path:", test_csv_path)
print("Test Image Folder:", test_image_folder)
print("CSV Exists:", os.path.exists(test_csv_path))
print("Contents of test folder:", os.listdir(test_inner_folder))

# Load test CSV
test_data = pd.read_csv(test_csv_path)
test_data["filepath"] = test_data["filename"].apply(lambda x: os.path.join(test_image_folder, x))

# Verify test data
print("Test data sample:")
print(test_data.head())
print("Number of test samples:", len(test_data))

# Define test data generator
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_data,
    x_col="filepath",
    y_col=None,
    target_size=(128, 128),
    batch_size=32,
    class_mode=None,
    shuffle=False
)

# Load the trained model (ensure best_model.h5 is in /kaggle/working/ or upload it)
model = load_model('/content/mobilenetv2.h5')  # Adjust path if different

# Make predictions
predictions = model.predict(test_generator, steps=len(test_data) // 32 + 1)

# Convert predictions to class labels
train_csv_path = os.path.join(dataset_path, "train (1)", "train", "train.csv")
train_data = pd.read_csv(train_csv_path)
class_labels = sorted(train_data["label"].unique())
predicted_classes = np.argmax(predictions, axis=1)
predicted_labels = [class_labels[idx] for idx in predicted_classes]

# Create and save results
results = pd.DataFrame({
    "filename": test_data["filename"],
    "predicted_label": predicted_labels
})

print("Sample predictions:")
print(results.head())

import os
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import load_model
import numpy as np
import matplotlib.pyplot as plt

test_data = pd.read_csv(test_csv_path)
test_data["filepath"] = test_data["filename"].apply(lambda x: os.path.join(test_image_folder, x))

for i in range(5):  # Display the first 5 images and predictions
    # Get the image path from test_data
    image_path = test_data["filepath"].iloc[i]

    # Load the image using Keras preprocessing
    img = load_img(image_path, target_size=(128, 128))  # Match model input size

    # Convert the image to an array
    img_array = img_to_array(img)

    # Plot the image
    plt.figure(figsize=(3, 3))
    plt.imshow(img_array / 255.0)  # Normalize to [0, 1] for display
    plt.axis('off')

    # Get the predicted label
    predicted_label = predicted_labels[i]
    plt.title(f"Predicted: {predicted_label}")

    # Show the image
    plt.show()

    # Optionally, print the label for verification
    print(f"Image {i + 1}: Predicted class: {predicted_label}")

import os
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import load_model
from sklearn.model_selection import train_test_split
import numpy as np

# Define paths for Kaggle environment
dataset_path = "/kaggle/input/wns-triange-hack-quest"
test_folder = os.path.join(dataset_path, "test (1)")
test_inner_folder = os.path.join(test_folder, "test")
test_csv_path = os.path.join(test_inner_folder, "test.csv")
test_image_folder = os.path.join(test_inner_folder, "images")

# Debugging: Verify paths and existence
print("Test CSV Path:", test_csv_path)
print("CSV Exists:", os.path.exists(test_csv_path))
print("Contents of test folder:", os.listdir(test_inner_folder))

# Load test CSV
test_data = pd.read_csv(test_csv_path)
test_data["filepath"] = test_data["filename"].apply(lambda x: os.path.join(test_image_folder, x))

# Verify test data
print("Test data sample:")
print(test_data.head())
print("Number of test samples:", len(test_data))

# Define test data generator
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_data,
    x_col="filepath",
    y_col=None,
    target_size=(128, 128),
    batch_size=32,
    class_mode=None,
    shuffle=False
)

# Load the trained model
model = load_model('/content/mobilenetv2.h5')

# Make predictions
predictions = model.predict(test_generator, steps=len(test_data) // 32 + 1)

# Convert predictions to class labels
train_csv_path = os.path.join(dataset_path, "train (1)", "train", "train.csv")
train_data = pd.read_csv(train_csv_path)
class_labels = sorted(train_data["label"].unique())
predicted_classes = np.argmax(predictions, axis=1)
predicted_labels = [class_labels[idx] for idx in predicted_classes]

# Create submission DataFrame (adjust based on competition rules)
results = pd.DataFrame({
    "filename": test_data["filename"],  # Or "image_id" if required
    "predicted_label": predicted_labels
})

print("Sample predictions:")
print(results.head())

# Optional: Provide validation metrics as a proxy
val_df = pd.read_csv("/kaggle/input/wns-triange-hack-quest/train (1)/train/train.csv")
train_df, val_df = train_test_split(val_df, test_size=0.2, random_state=42)
val_df["filepath"] = val_df["filename"].apply(lambda x: os.path.join("/kaggle/input/wns-triange-hack-quest/train (1)/train/images", x))

val_df['label'] = val_df['label'].astype(str)

val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
val_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    x_col="filepath",
    y_col="label",
    target_size=(128, 128),
    batch_size=32,
    class_mode="categorical"
)

val_loss, val_accuracy = model.evaluate(val_generator)
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy * 100:.2f}% (Proxy for test performance)")

!pip install transformers

from transformers import BlipProcessor, BlipForConditionalGeneration
import torch
from PIL import Image

# Load the pre-trained BLIP model and processor
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
caption_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Visualize and explain the first 5 predictions
for i in range(5):
    # Load image for visualization
    image_path = test_data["filepath"].iloc[i]
    img = load_img(image_path, target_size=(128, 128))  # Adjust size as per your model
    img_array = img_to_array(img)

    # Display the image
    plt.figure(figsize=(4, 4))
    plt.imshow(img_array / 255.0)  # Normalize for display
    plt.axis("off")

    # Get the predicted label
    predicted_label = predicted_labels[i]

    # Generate caption
    image = Image.open(image_path).convert("RGB")  # Load full image for captioning
    inputs = processor(image, return_tensors="pt")
    with torch.no_grad():
        output = caption_model.generate(**inputs)
        caption = processor.decode(output[0], skip_special_tokens=True)

    # Create text explanation
    explanation = f"The model predicted '{predicted_label}' based on the image content: '{caption}'."

    # Add title with prediction and explanation
    plt.title(f"Predicted: {predicted_label}\nExplanation: {explanation}", fontsize=10)
    plt.show()

    # Print explanation
    print(explanation)