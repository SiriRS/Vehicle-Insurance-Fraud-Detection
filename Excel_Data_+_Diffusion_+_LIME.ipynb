{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install required libraries\n",
        "!pip install pandas numpy scikit-learn imbalanced-learn xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZJIDfhNIaXZ",
        "outputId": "d7a210ef-fc01-4b7b-95a7-ea0b1d14ae53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDXEI61SFnSA"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (upload your file to Colab and update the path)\n",
        "data = pd.read_csv('/content/carclaims.csv')\n",
        "\n",
        "# Convert 'FraudFound' to binary (Yes=1, No=0)\n",
        "data['FraudFound'] = data['FraudFound'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('FraudFound', axis=1)\n",
        "y = data['FraudFound']\n",
        "\n",
        "# Handle categorical variables with one-hot encoding\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Check initial class distribution\n",
        "print(\"Initial Class Distribution:\")\n",
        "print(y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT7bpj7yIcYv",
        "outputId": "ac66e81d-82da-47ae-8e69-e9a7987c2260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Class Distribution:\n",
            "FraudFound\n",
            "0    10148\n",
            "1      646\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(pd.Series(y_train_smote).value_counts())\n",
        "\n",
        "# Apply ADASYN\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
        "print(\"\\nAfter ADASYN:\")\n",
        "print(pd.Series(y_train_adasyn).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGKM0bpIfaq",
        "outputId": "4b5c0fd1-36d6-4000-eff7-341f61bfdac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After SMOTE:\n",
            "FraudFound\n",
            "0    10148\n",
            "1    10148\n",
            "Name: count, dtype: int64\n",
            "\n",
            "After ADASYN:\n",
            "FraudFound\n",
            "0    10148\n",
            "1     9931\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=5000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": xgb.XGBClassifier(eval_metric='logloss', random_state=42),\n",
        "    \"SVM\": SVC(probability=True, random_state=42),\n",
        "    \"Balanced Bagging\": BalancedBaggingClassifier(estimator=RandomForestClassifier(n_estimators=10),\n",
        "                                                  n_estimators=10, random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "wW4oxJDoJQGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define k-fold cross-validation (reduced to 3 folds for speed)\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# Function to evaluate model with cross-validation\n",
        "def evaluate_model(model, X_train_fold, y_train_fold, X_val_fold, y_val_fold, name, balancing_method=\"SMOTE\"):\n",
        "    # Apply balancing within the fold\n",
        "    if balancing_method == \"SMOTE\":\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_bal, y_bal = smote.fit_resample(X_train_fold, y_train_fold)\n",
        "    elif balancing_method == \"ADASYN\":\n",
        "        adasyn = ADASYN(random_state=42)\n",
        "        X_bal, y_bal = adasyn.fit_resample(X_train_fold, y_train_fold)\n",
        "    else:  # For Balanced Bagging or no balancing\n",
        "        X_bal, y_bal = X_train_fold, y_train_fold\n",
        "\n",
        "    # Train on balanced fold data\n",
        "    model.fit(X_bal, y_bal)\n",
        "\n",
        "    # Evaluate on validation fold (original data)\n",
        "    y_pred_val = model.predict(X_val_fold)\n",
        "    y_pred_proba_val = model.predict_proba(X_val_fold)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_val_fold)\n",
        "\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"Balancing\": balancing_method,\n",
        "        \"Accuracy\": accuracy_score(y_val_fold, y_pred_val),\n",
        "        \"Precision\": precision_score(y_val_fold, y_pred_val),\n",
        "        \"Recall\": recall_score(y_val_fold, y_pred_val),\n",
        "        \"F1-Score\": f1_score(y_val_fold, y_pred_val),\n",
        "        \"AUC-PR\": roc_auc_score(y_val_fold, y_pred_proba_val)\n",
        "    }\n",
        "\n",
        "# Evaluate models with SMOTE only (for speed; add ADASYN later if needed)\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    fold_results = []\n",
        "    for train_index, val_index in skf.split(X_train, y_train):\n",
        "        # Convert indices to integer type for NumPy array indexing\n",
        "        train_index = train_index.astype(int)\n",
        "        val_index = val_index.astype(int)\n",
        "\n",
        "        # Ensure X_train is a NumPy array for integer indexing\n",
        "        X_train_np = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
        "        X_train_fold, X_val_fold = X_train_np[train_index], X_train_np[val_index]\n",
        "\n",
        "        # Ensure y_train is a pandas Series or NumPy array and index properly\n",
        "        y_train_series = y_train if isinstance(y_train, pd.Series) else pd.Series(y_train)\n",
        "        y_train_fold, y_val_fold = y_train_series.iloc[train_index], y_train_series.iloc[val_index]\n",
        "\n",
        "        # Evaluate with appropriate balancing method\n",
        "        if name == \"Balanced Bagging\":\n",
        "            result = evaluate_model(model, X_train_fold, y_train_fold, X_val_fold, y_val_fold, name, \"None\")\n",
        "        else:\n",
        "            result = evaluate_model(model, X_train_fold, y_train_fold, X_val_fold, y_val_fold, name, \"SMOTE\")\n",
        "        fold_results.append(result)\n",
        "\n",
        "    # Average results across folds\n",
        "    avg_result = {\n",
        "        \"Model\": name,\n",
        "        \"Balancing\": \"None\" if name == \"Balanced Bagging\" else \"SMOTE\",\n",
        "        \"Accuracy\": np.mean([r[\"Accuracy\"] for r in fold_results]),\n",
        "        \"Precision\": np.mean([r[\"Precision\"] for r in fold_results]),\n",
        "        \"Recall\": np.mean([r[\"Recall\"] for r in fold_results]),\n",
        "        \"F1-Score\": np.mean([r[\"F1-Score\"] for r in fold_results]),\n",
        "        \"AUC-PR\": np.mean([r[\"AUC-PR\"] for r in fold_results])\n",
        "    }\n",
        "    results.append(avg_result)\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nCross-Validation Results (Averaged Over Folds):\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZGZVAV1RR8A",
        "outputId": "32b1d0fb-031d-4d11-82b2-7db288f4e7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-Validation Results (Averaged Over Folds):\n",
            "                 Model Balancing  Accuracy  Precision    Recall  F1-Score  \\\n",
            "0  Logistic Regression     SMOTE  0.695016   0.134737  0.755434  0.228685   \n",
            "1        Random Forest     SMOTE  0.939596   0.375000  0.004644  0.009121   \n",
            "2              XGBoost     SMOTE  0.948027   0.727076  0.210515  0.326479   \n",
            "3                  SVM     SMOTE  0.905688   0.198281  0.188831  0.193177   \n",
            "4     Balanced Bagging      None  0.716972   0.149381  0.794050  0.251400   \n",
            "\n",
            "     AUC-PR  \n",
            "0  0.791316  \n",
            "1  0.798214  \n",
            "2  0.935311  \n",
            "3  0.758967  \n",
            "4  0.820920  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models on full SMOTE-balanced data and evaluate on test set\n",
        "test_results = {}\n",
        "for name, model in models.items():\n",
        "    if name == \"Balanced Bagging\":\n",
        "        model.fit(X_train, y_train)  # Balanced Bagging uses original data\n",
        "    else:\n",
        "        model.fit(X_train_smote, y_train_smote)  # Others use SMOTE data\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test)\n",
        "\n",
        "    test_results[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-PR\": roc_auc_score(y_test, y_pred_proba)\n",
        "    }\n",
        "    print(f\"\\n{name} Test Set Results:\")\n",
        "    for metric, value in test_results[name].items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "test_results_df = pd.DataFrame(test_results).T\n",
        "print(\"\\nTest Set Comparison:\")\n",
        "print(test_results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4pQShxUJVZ3",
        "outputId": "2f92765a-01e1-44f2-9e56-05b6f10c069c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Test Set Results:\n",
            "Accuracy: 0.6747\n",
            "Precision: 0.1292\n",
            "Recall: 0.7726\n",
            "F1-Score: 0.2214\n",
            "AUC-PR: 0.7927\n",
            "\n",
            "Random Forest Test Set Results:\n",
            "Accuracy: 0.9401\n",
            "Precision: 0.5000\n",
            "Recall: 0.0108\n",
            "F1-Score: 0.0212\n",
            "AUC-PR: 0.8058\n",
            "\n",
            "XGBoost Test Set Results:\n",
            "Accuracy: 0.9589\n",
            "Precision: 0.8537\n",
            "Recall: 0.3791\n",
            "F1-Score: 0.5250\n",
            "AUC-PR: 0.9685\n",
            "\n",
            "SVM Test Set Results:\n",
            "Accuracy: 0.8962\n",
            "Precision: 0.1896\n",
            "Recall: 0.2238\n",
            "F1-Score: 0.2053\n",
            "AUC-PR: 0.7795\n",
            "\n",
            "Balanced Bagging Test Set Results:\n",
            "Accuracy: 0.7198\n",
            "Precision: 0.1555\n",
            "Recall: 0.8303\n",
            "F1-Score: 0.2620\n",
            "AUC-PR: 0.8384\n",
            "\n",
            "Test Set Comparison:\n",
            "                     Accuracy  Precision    Recall  F1-Score    AUC-PR\n",
            "Logistic Regression  0.674665   0.129227  0.772563  0.221417  0.792735\n",
            "Random Forest        0.940121   0.500000  0.010830  0.021201  0.805822\n",
            "XGBoost              0.958928   0.853659  0.379061  0.525000  0.968544\n",
            "SVM                  0.896239   0.189602  0.223827  0.205298  0.779503\n",
            "Balanced Bagging     0.719844   0.155510  0.830325  0.261959  0.838393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume `model` is your trained model and `df_scaled` is your input\n",
        "prediction = model.predict(df_scaled)[0]  # 0 or 1\n",
        "confidence = model.predict_proba(df_scaled)[0][1]  # Probability of class '1' (fraud)\n"
      ],
      "metadata": {
        "id": "BAaFqoIWsW-I",
        "outputId": "898c9ce5-acc5-4c4b-d409-4042105d645c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_scaled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-10c75533a7ba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assume `model` is your trained model and `df_scaled` is your input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Probability of class '1' (fraud)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_scaled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save all models to a single pickle file\n",
        "with open('trained_models.pkl', 'wb') as f:\n",
        "    pickle.dump(models, f)\n"
      ],
      "metadata": {
        "id": "tHAGOFJQSoYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ensemble\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', models[\"Logistic Regression\"]),\n",
        "        ('rf', models[\"Random Forest\"]),\n",
        "        ('xgb', models[\"XGBoost\"]),\n",
        "        ('svm', models[\"SVM\"]),\n",
        "        ('bb', models[\"Balanced Bagging\"])\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "# Train ensemble on SMOTE-balanced data\n",
        "ensemble.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_ensemble = ensemble.predict(X_test)\n",
        "y_pred_proba_ensemble = ensemble.predict_proba(X_test)[:, 1]\n",
        "\n",
        "ensemble_results = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_ensemble),\n",
        "    \"Precision\": precision_score(y_test, y_pred_ensemble),\n",
        "    \"Recall\": recall_score(y_test, y_pred_ensemble),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred_ensemble),\n",
        "    \"AUC-PR\": roc_auc_score(y_test, y_pred_proba_ensemble)\n",
        "}\n",
        "\n",
        "print(\"\\nEnsemble (Voting Classifier) Test Set Results:\")\n",
        "for metric, value in ensemble_results.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKkPtIIRJXxF",
        "outputId": "0956b2f0-038e-4803-ef86-a37581e58bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ensemble (Voting Classifier) Test Set Results:\n",
            "Accuracy: 0.9406\n",
            "Precision: 0.5227\n",
            "Recall: 0.0830\n",
            "F1-Score: 0.1433\n",
            "AUC-PR: 0.8839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ensemble with weights\n",
        "ensemble_weighted = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', models[\"Logistic Regression\"]),\n",
        "        ('rf', models[\"Random Forest\"]),\n",
        "        ('xgb', models[\"XGBoost\"]),\n",
        "        ('svm', models[\"SVM\"]),\n",
        "        ('bb', models[\"Balanced Bagging\"])\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[0.1, 0.3, 0.5, 0.05, 0.05]  # Higher weight for XGBoost (0.5), RF (0.3)\n",
        ")\n",
        "\n",
        "# Train ensemble on SMOTE-balanced data\n",
        "ensemble_weighted.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred_ensemble = ensemble_weighted.predict(X_test)\n",
        "y_pred_proba_ensemble = ensemble_weighted.predict_proba(X_test)[:, 1]\n",
        "\n",
        "ensemble_results = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_ensemble),\n",
        "    \"Precision\": precision_score(y_test, y_pred_ensemble),\n",
        "    \"Recall\": recall_score(y_test, y_pred_ensemble),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred_ensemble),\n",
        "    \"AUC-PR\": roc_auc_score(y_test, y_pred_proba_ensemble)\n",
        "}\n",
        "\n",
        "print(\"\\nWeighted Ensemble (Voting Classifier) Test Set Results:\")\n",
        "for metric, value in ensemble_results.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdm-t7gvJbKE",
        "outputId": "a240326f-4e16-4f0d-b4a8-fd06c60d646b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weighted Ensemble (Voting Classifier) Test Set Results:\n",
            "Accuracy: 0.9488\n",
            "Precision: 0.8846\n",
            "Recall: 0.1661\n",
            "F1-Score: 0.2796\n",
            "AUC-PR: 0.9367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ensemble with only XGBoost and Random Forest\n",
        "ensemble_subset = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', models[\"Random Forest\"]),\n",
        "        ('xgb', models[\"XGBoost\"])\n",
        "    ],\n",
        "    voting='soft',\n",
        "    weights=[0.3, 0.7]  # Favor XGBoost slightly more\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "ensemble_subset.fit(X_train_smote, y_train_smote)\n",
        "y_pred_ensemble = ensemble_subset.predict(X_test)\n",
        "y_pred_proba_ensemble = ensemble_subset.predict_proba(X_test)[:, 1]\n",
        "\n",
        "ensemble_results = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred_ensemble),\n",
        "    \"Precision\": precision_score(y_test, y_pred_ensemble),\n",
        "    \"Recall\": recall_score(y_test, y_pred_ensemble),\n",
        "    \"F1-Score\": f1_score(y_test, y_pred_ensemble),\n",
        "    \"AUC-PR\": roc_auc_score(y_test, y_pred_proba_ensemble)\n",
        "}\n",
        "\n",
        "print(\"\\nSubset Ensemble (XGBoost + RF) Test Set Results:\")\n",
        "for metric, value in ensemble_results.items():\n",
        "    print(f\"{metric}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRf3RyF2VTKm",
        "outputId": "b8e12cc7-3ccf-43b3-dca5-2057d3d5c09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Subset Ensemble (XGBoost + RF) Test Set Results:\n",
            "Accuracy: 0.9516\n",
            "Precision: 0.8841\n",
            "Recall: 0.2202\n",
            "F1-Score: 0.3526\n",
            "AUC-PR: 0.9522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SHAP"
      ],
      "metadata": {
        "id": "HPh_rBvxBDAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CQrk3XsBEMx",
        "outputId": "44042c08-9030-4ba5-dfe7-e05beaf044ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m266.2/275.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=1b92d1414859e495faf8ff38394807dab270c486bea0484d81a4906112f98d2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lime\n",
        "import lime.lime_tabular\n",
        "import numpy as np\n",
        "\n",
        "# Create LIME explainer\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=np.array(X_train),\n",
        "    feature_names=X.columns.tolist(),\n",
        "    class_names=np.unique(y_train).astype(str),\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# Loop through your models\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"\\nExplaining prediction with LIME for {name}...\")\n",
        "    i = 0  # Index of the test instance to explain\n",
        "    exp = explainer.explain_instance(\n",
        "        data_row=X_test[i],\n",
        "        predict_fn=model.predict_proba,\n",
        "        num_features=5\n",
        "    )\n",
        "\n",
        "    # Text explanation\n",
        "    print(f\"\\nTextual explanation for model: {name}\")\n",
        "    for feature, weight in exp.as_list():\n",
        "        direction = \"increased\" if weight > 0 else \"decreased\"\n",
        "        print(f\" - {feature} {direction} the prediction confidence by {abs(weight):.4f}\")\n",
        "\n",
        "    # Optional: show HTML visualization (in Jupyter Notebook)\n",
        "    # exp.show_in_notebook()\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 60 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qF74AFFENgD",
        "outputId": "808fda9a-f8e6-4ea8-8c9e-0ae2c6ac6e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "\n",
            "Explaining prediction with LIME for Logistic Regression...\n",
            "\n",
            "Textual explanation for model: Logistic Regression\n",
            " - PolicyType_Sport - Collision <= -0.15 decreased the prediction confidence by 0.0699\n",
            " - AddressChange-Claim_2 to 3 years <= -0.14 decreased the prediction confidence by 0.0433\n",
            " - AgeOfVehicle_5 years <= -0.32 decreased the prediction confidence by 0.0252\n",
            " - Fault_Third Party <= -0.61 increased the prediction confidence by 0.0210\n",
            " - MaritalStatus_Single <= -0.67 decreased the prediction confidence by 0.0158\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training Random Forest...\n",
            "\n",
            "Explaining prediction with LIME for Random Forest...\n",
            "\n",
            "Textual explanation for model: Random Forest\n",
            " - Fault_Third Party <= -0.61 increased the prediction confidence by 0.0728\n",
            " - AddressChange-Claim_2 to 3 years <= -0.14 decreased the prediction confidence by 0.0474\n",
            " - -0.70 < BasePolicy_Liability <= 1.44 decreased the prediction confidence by 0.0350\n",
            " - -0.69 < PolicyType_Sedan - Liability <= 1.44 decreased the prediction confidence by 0.0348\n",
            " - PolicyType_Sedan - Collision <= -0.76 increased the prediction confidence by 0.0119\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training XGBoost...\n",
            "\n",
            "Explaining prediction with LIME for XGBoost...\n",
            "\n",
            "Textual explanation for model: XGBoost\n",
            " - AddressChange-Claim_2 to 3 years <= -0.14 decreased the prediction confidence by 0.0758\n",
            " - -0.70 < BasePolicy_Liability <= 1.44 decreased the prediction confidence by 0.0448\n",
            " - Fault_Third Party <= -0.61 increased the prediction confidence by 0.0421\n",
            " - Month_Oct > -0.30 decreased the prediction confidence by 0.0201\n",
            " - PolicyType_Sedan - Collision <= -0.76 increased the prediction confidence by 0.0139\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training SVM...\n",
            "\n",
            "Explaining prediction with LIME for SVM...\n",
            "\n",
            "Textual explanation for model: SVM\n",
            " - AddressChange-Claim_under 6 months <= -0.02 decreased the prediction confidence by 0.6019\n",
            " - AddressChange-Claim_2 to 3 years <= -0.14 decreased the prediction confidence by 0.0904\n",
            " - PolicyType_Sport - Collision <= -0.15 decreased the prediction confidence by 0.0510\n",
            " - AgeOfVehicle_4 years <= -0.12 decreased the prediction confidence by 0.0510\n",
            " - Fault_Third Party <= -0.61 increased the prediction confidence by 0.0166\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training Balanced Bagging...\n",
            "\n",
            "Explaining prediction with LIME for Balanced Bagging...\n",
            "\n",
            "Textual explanation for model: Balanced Bagging\n",
            " - Fault_Third Party <= -0.61 increased the prediction confidence by 0.2520\n",
            " - -0.70 < BasePolicy_Liability <= 1.44 decreased the prediction confidence by 0.1378\n",
            " - -0.69 < PolicyType_Sedan - Liability <= 1.44 decreased the prediction confidence by 0.0950\n",
            " - -0.73 < VehicleCategory_Sport <= 1.37 decreased the prediction confidence by 0.0668\n",
            " - Deductible <= -0.18 decreased the prediction confidence by 0.0508\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aAf3Vh3Em2ss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}